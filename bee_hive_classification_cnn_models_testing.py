# -*- coding: utf-8 -*-
"""Bee_hive_classification- CNN models testing

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14Q_Pq6bGWuNk4kw_Cie5pZxTNSH8B2gv
"""

from tensorflow import keras
from keras_preprocessing import image
import numpy as np
import tensorflow as tf
from keras_preprocessing.image import ImageDataGenerator

import keras
from keras.models import *
from keras.layers import *
from keras.optimizers import *

pip install visualkeras # Since colab doesn't have this visualization tool we have to install it. If your device already has this module ignore it

import visualkeras

#Importing images

width=150
height=150
train_datagen = ImageDataGenerator(
    rescale=1./255)

test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    "/content/drive/MyDrive/Bee_data/train", target_size=(width,height), batch_size=20, class_mode='categorical')


validation_generator = test_datagen.flow_from_directory(
    "/content/drive/MyDrive/Bee_data/val", target_size=(width,height), batch_size=20,class_mode='categorical')

#Model 1

model=Sequential()
model.add(Conv2D(32,kernel_size=3,activation='relu',input_shape=(150,150,3)))
model.add(MaxPool2D(strides=(2,2)))

model.add(Flatten())
model.add(Dense(512,activation='relu'))
model.add(Dense(128,activation='relu'))
model.add(Dense(10,activation='softmax'))


model.summary()

visualkeras.layered_view(model).show() # display using your system viewer


visualkeras.layered_view(model)

rms=keras.optimizers.RMSprop(learning_rate=0.05,rho=0.9)
model.compile(loss="categorical_crossentropy",optimizer='adam',metrics=['categorical_accuracy'])

from keras.callbacks import History
history=History()
model.fit_generator(train_generator,
                    steps_per_epoch=100,
                    epochs=10,
                    callbacks=[history],
                    validation_data=validation_generator,
                    validation_steps=40)

# Plot training & validation accuracy values
plt.figure(figsize=(9,4))

plt.subplot(1,2,1)
plt.plot(history.history['categorical_accuracy'])
plt.plot(history.history['val_categorical_accuracy'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train accuracy', 'Test accuracy'], loc='upper left')

# Plot training & validation loss values
plt.subplot(1,2,2)
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train loss', 'Test loss'], loc='upper left')
plt.show()

model2=Sequential()
model2.add(Conv2D(32,kernel_size=3,activation='relu',input_shape=(150,150,3)))
model2.add(BatchNormalization())
model2.add(MaxPool2D(strides=(2,2)))
model2.add(Dropout(0.3))
model2.add(Flatten())
model2.add(Dense(512,activation='relu'))
model2.add(Dense(128,activation='relu'))
model2.add(Dense(10,activation='softmax'))
model2.summary()

visualkeras.layered_view(model2).show() # display using your system viewer


visualkeras.layered_view(model2)

model2.compile(loss="categorical_crossentropy",optimizer='adam',metrics=['categorical_accuracy'])

from keras.callbacks import History
history2=History()
model2.fit_generator(train_generator,
                    steps_per_epoch=100,
                    epochs=10,
                    callbacks=[history2],
                    validation_data=validation_generator,
                    validation_steps=40)

# Plot training & validation accuracy values
import matplotlib.pyplot as plt

plt.figure(figsize=(9,4))

plt.subplot(1,2,1)
plt.plot(history2.history['categorical_accuracy'])
plt.plot(history2.history['val_categorical_accuracy'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train accuracy', 'Test accuracy'], loc='upper left')

# Plot training & validation loss values
plt.subplot(1,2,2)
plt.plot(history2.history['loss'])
plt.plot(history2.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train loss', 'Test loss'], loc='upper left')
plt.show()

model3=Sequential()
model3.add(Conv2D(32,kernel_size=3,activation='relu',input_shape=(150,150,3)))
model3.add(Conv2D(32,kernel_size=3,activation='relu'))
model3.add(BatchNormalization())
model3.add(MaxPool2D(strides=(2,2)))
model3.add(Dropout(0.3))
model3.add(Conv2D(64,kernel_size=5,activation='relu'))
model3.add(Conv2D(64,kernel_size=5,activation='relu'))
model3.add(BatchNormalization())
model3.add(MaxPool2D(strides=(2,2)))
model3.add(Dropout(0.3))
model3.add(Flatten())
model3.add(Dense(512,activation='relu'))
model3.add(Dense(128,activation='relu'))
model3.add(Dense(10,activation='softmax'))

visualkeras.layered_view(model3).show() # display using your system viewer


visualkeras.layered_view(model3)

model3.summary()

model3.compile(loss="categorical_crossentropy",optimizer='adam',metrics=['categorical_accuracy'])

history3=model.fit_generator(train_generator,
                    steps_per_epoch=100,
                    epochs=10,
                    
                    validation_data=validation_generator,
                    validation_steps=40)

# Plot training & validation accuracy values
import matplotlib.pyplot as plt

plt.figure(figsize=(9,4))

plt.subplot(1,2,1)
plt.plot(history3.history['categorical_accuracy'])
plt.plot(history3.history['val_categorical_accuracy'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train accuracy', 'Test accuracy'], loc='upper left')

# Plot training & validation loss values
plt.subplot(1,2,2)
plt.plot(history3.history['loss'])
plt.plot(history3.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train loss', 'Test loss'], loc='upper left')
plt.show()
